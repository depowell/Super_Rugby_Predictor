{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018']\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime as dt\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# comprehend list for years\n",
    "years = [str(2000 + i) for i in range(5,19)]\n",
    "this_year = '2019'\n",
    "print(years)\n",
    "\n",
    "# where do we get the data?\n",
    "current_year_url = 'http://www.superrugby.co.nz/Grandstand'\n",
    "url = 'http://www.superrugby.co.nz/Grandstand/HistoricalResults/' # year appends here\n",
    "\n",
    "# getter function\n",
    "def get_rugby_data(url, year):\n",
    "    '''getting data from super rugby website'''\n",
    "    if year == this_year:\n",
    "        x = ''\n",
    "    else:\n",
    "        x = year\n",
    "    page = requests.get(url + x)\n",
    "    soup = bs(page.text, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all previous years data: run this once\n",
    "for i in years:\n",
    "    data = get_rugby_data(url, i)\n",
    "    f = open(\"data/data_\" + i + \".txt\",\"w+\")\n",
    "    f.write(str(data))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get this years data, run this after every round\n",
    "data = get_rugby_data(current_year_url, this_year)\n",
    "f = open(\"data/data_\" + this_year + \".txt\",\"w+\")\n",
    "f.write(str(data))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple functions for cleaning data\n",
    "# regex for finding round names\n",
    "pattern = re.compile(\"^(Round|Week|Semifinal|Final|Qualifiers|Semis)(\\ \\d{1,2})?.*$\")\n",
    "\n",
    "def parse_date(date):\n",
    "    date = dt.datetime.strptime(date, '%d %b %Y')\n",
    "    return date\n",
    "\n",
    "def outcome(f):\n",
    "    '''game outcome for home team V: victory L: loss D: draw'''\n",
    "    if f > 0:\n",
    "        return 'V'\n",
    "    elif f < 0:\n",
    "        return 'L'\n",
    "    elif f == 0:\n",
    "        return 'D'\n",
    "    else:\n",
    "        return 'D'\n",
    "\n",
    "def fix_round(f):\n",
    "    '''extract round number or final type'''\n",
    "    if f[:4] == 'Week':\n",
    "        return f[5:7]\n",
    "    elif f[:5] == 'Round':\n",
    "        return f[6:8]\n",
    "    elif f[:10] == 'Qualifiers' or f[:13] == 'Quarterfinals':\n",
    "        return 'QF' # quarter final\n",
    "    elif f[:6] == 'Finals' or f == 'Semifinals' or f == 'Semis' or f == 'Semifinal':\n",
    "        return 'SF' # semi final\n",
    "    elif f[:6] == 'Final ' or f == 'Final':\n",
    "        return 'GF' # grand final\n",
    "    else:\n",
    "        return f\n",
    "    \n",
    "def data_nice(year):\n",
    "    table_nice = []\n",
    "    table_round = []\n",
    "    with open('data/data_' + year + '.txt') as f:\n",
    "        data = bs(f.read())\n",
    "    rows = data.find_all('tr')\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        cols_nice = [ele.text.strip() for ele in cols]\n",
    "        cols_round = [x.text.strip() for x in cols if pattern.match(x.text.strip())]\n",
    "        table_nice.append([ele for ele in cols_nice if ele]) # Get rid of empty values\n",
    "        table_round.append([ele for ele in cols_round if ele]) # Get rid of empty values\n",
    "    df1 = pd.DataFrame(table_nice)\n",
    "    df2 = pd.DataFrame(table_round).fillna(method='ffill')\n",
    "    df = pd.concat([df1, df2], axis=1).dropna()\n",
    "    df['year'] = year\n",
    "    df.columns = ['date','teams','location','time','score','round','year']\n",
    "    df['date'] = df['date'] + ' ' + df['year']\n",
    "    df['home'] = df['teams'].str.split(' v ').str[0]\n",
    "    df['away'] = df['teams'].str.split(' v ').str[1]\n",
    "    df['home'] = df['home'].str.strip()\n",
    "    df['away'] = df['away'].str.strip()\n",
    "    df['fthp'] = df['score'].str.split('-').str[0].astype('int') # full time home points\n",
    "    df['ftap'] = df['score'].str.split('-').str[1].astype('int') # full time away points\n",
    "    df['ftr'] = [outcome(x) for x in df['fthp'] - df['ftap']] # home outcome ftr (full time result)\n",
    "    df['round'] = [fix_round(x) for x in df['round']]\n",
    "    remove_columns = ['teams','score','year','location','time']\n",
    "    df = df.drop(columns=remove_columns)\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframes, cleaning up data:\n",
    "\n",
    "df_2005 = data_nice('2005')\n",
    "df_2006 = data_nice('2006')\n",
    "df_2007 = data_nice('2007')\n",
    "df_2008 = data_nice('2008')\n",
    "df_2009 = data_nice('2009')\n",
    "df_2010 = data_nice('2010')\n",
    "df_2011 = data_nice('2011')\n",
    "df_2012 = data_nice('2012')\n",
    "df_2013 = data_nice('2013')\n",
    "df_2014 = data_nice('2014')\n",
    "df_2015 = data_nice('2015')\n",
    "df_2016 = data_nice('2016')\n",
    "df_2017 = data_nice('2017')\n",
    "df_2018 = data_nice('2018')\n",
    "df_2019 = data_nice('2019')\n",
    "\n",
    "# more fixing data inconsistancies\n",
    "df_2005.loc[(df_2005['date'] == '28 May 2005'), 'round'] = \"GF\" # 2005 no final fixed\n",
    "df_2006.drop(5, inplace=True) # remove bogus final data from 2006\n",
    "df_2018.drop(10, inplace=True) # remove bogus final data from 2018\n",
    "# List of series missing from each year\n",
    "missing_games_2007 = [pd.Series(['12 May 2007', 'SF',\n",
    "                           'Sharks', 'Blues', \n",
    "                           34, 18, 'V'], index=df_2007.columns ) ,\n",
    "                      pd.Series(['12 May 2007', 'SF', \n",
    "                           'Bulls', 'Crusaders', \n",
    "                           27, 12, 'V'], index=df_2007.columns )]\n",
    "\n",
    "missing_games_2008 = [pd.Series(['31 May 2008', 'GF',\n",
    "                           'Crusaders', 'Waratahs', \n",
    "                           20, 12, 'V'], index=df_2008.columns ) ,\n",
    "                      pd.Series(['24 May 2008', 'SF', \n",
    "                           'Waratahs', 'Sharks', \n",
    "                           28, 13, 'V'], index=df_2008.columns ),\n",
    "                      pd.Series(['24 May 2008', 'SF', \n",
    "                           'Crusaders', 'Hurricanes', \n",
    "                           33, 22, 'V'], index=df_2008.columns )]\n",
    "\n",
    "missing_games_2017 = [pd.Series(['21 Jul 2017', 'QF',\n",
    "                           'Brumbies', 'Hurricanes', \n",
    "                           16, 35, 'L'], index=df_2017.columns ) ,\n",
    "                      \n",
    "                      pd.Series(['22 Jul 2017', 'QF', \n",
    "                           'Crusaders', 'Highlanders', \n",
    "                           17, 0, 'V'], index=df_2017.columns ),\n",
    "                      \n",
    "                      pd.Series(['23 Jul 2017', 'QF', \n",
    "                           'Lions', 'Sharks', \n",
    "                           23, 21, 'V'], index=df_2017.columns ),\n",
    "                      \n",
    "                      pd.Series(['23 Jul 2017', 'QF', \n",
    "                           'Stormers', 'Chiefs', \n",
    "                           11, 17, 'L'], index=df_2017.columns )]\n",
    "\n",
    "# Pass a list of series to the append() to add multiple rows to 2007\n",
    "df_2007 = df_2007.append(missing_games_2007 , ignore_index=True)\n",
    "df_2008 = df_2008.append(missing_games_2008 , ignore_index=True)\n",
    "df_2017 = df_2017.append(missing_games_2017 , ignore_index=True)\n",
    "\n",
    "\n",
    "df_2009.at[6, 'home'] = 'Chiefs'\n",
    "df_2009.at[7, 'home'] = 'Bulls'\n",
    "df_2009.at[8, 'home'] = 'Bulls'\n",
    "\n",
    "df_2010.at[4, 'home'] = 'Bulls'\n",
    "\n",
    "df_2013.at[2, 'home'] = 'Crusaders'\n",
    "df_2013.at[3, 'home'] = 'Brumbies'\n",
    "df_2013.at[4, 'home'] = 'Chiefs'\n",
    "df_2013.at[5, 'home'] = 'Bulls'\n",
    "df_2013.at[6, 'home'] = 'Chiefs'\n",
    "\n",
    "df_2014.at[6, 'round'] = 'GF'\n",
    "df_2014.at[2, 'round'] = 'QF'\n",
    "df_2014.at[3, 'round'] = 'QF'\n",
    "\n",
    "df_2015.at[2, 'round'] = 'QF'\n",
    "df_2015.at[3, 'round'] = 'QF'\n",
    "df_2015.at[6, 'round'] = 'GF'\n",
    "\n",
    "df_2016.at[2, 'round'] = 'QF'\n",
    "df_2016.at[3, 'round'] = 'QF'\n",
    "df_2016.at[4, 'round'] = 'QF'\n",
    "df_2016.at[5, 'round'] = 'QF'\n",
    "df_2016.at[8, 'round'] = 'GF'\n",
    "\n",
    "df_2016.at[6, 'home'] = 'Crusaders'\n",
    "df_2016.at[7, 'home'] = 'Lions'\n",
    "\n",
    "df_2018.at[152, 'round'] = 'QF'\n",
    "df_2018.at[153, 'round'] = 'QF'\n",
    "df_2018.at[154, 'round'] = 'QF'\n",
    "df_2018.at[155, 'round'] = 'QF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'playing_stat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-41c670d91a1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaying_stat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'playing_stat' is not defined"
     ]
    }
   ],
   "source": [
    "print(playing_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'round', 'home', 'away', 'fthp', 'ftap', 'ftr', 'htps', 'htpc',\n",
       "       'atps', 'atpc', 'htp', 'atp', 'hm1', 'hm2', 'hm3', 'hm4', 'hm5', 'am1',\n",
       "       'am2', 'am3', 'am4', 'am5', 'rn', 'htformptsstr', 'atformptsstr',\n",
       "       'htformpts', 'atformpts', 'HTWinStreak3', 'HTWinStreak5',\n",
       "       'HTLossStreak3', 'HTLossStreak5', 'ATWinStreak3', 'ATWinStreak5',\n",
       "       'ATLossStreak3', 'ATLossStreak5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018']\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime as dt\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# comprehend list for years\n",
    "years = [str(2000 + i) for i in range(5,19)]\n",
    "this_year = '2019'\n",
    "print(years)\n",
    "\n",
    "# where do we get the data?\n",
    "current_year_url = 'http://www.superrugby.co.nz/Grandstand'\n",
    "url = 'http://www.superrugby.co.nz/Grandstand/HistoricalResults/' # year appends here\n",
    "\n",
    "# getter function\n",
    "def get_rugby_data(url, year):\n",
    "    '''getting data from super rugby website'''\n",
    "    if year == this_year:\n",
    "        x = ''\n",
    "    else:\n",
    "        x = year\n",
    "    page = requests.get(url + x)\n",
    "    soup = bs(page.text, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all previous years data: run this once\n",
    "for i in years:\n",
    "    data = get_rugby_data(url, i)\n",
    "    f = open(\"data/data_\" + i + \".txt\",\"w+\")\n",
    "    f.write(str(data))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get this years data, run this after every round\n",
    "data = get_rugby_data(current_year_url, this_year)\n",
    "f = open(\"data/data_\" + this_year + \".txt\",\"w+\")\n",
    "f.write(str(data))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple functions for cleaning data\n",
    "# regex for finding round names\n",
    "pattern = re.compile(\"^(Round|Week|Semifinal|Final|Qualifiers|Semis)(\\ \\d{1,2})?.*$\")\n",
    "\n",
    "def parse_date(date):\n",
    "    date = dt.datetime.strptime(date, '%d %b %Y')\n",
    "    return date\n",
    "\n",
    "def outcome(f):\n",
    "    '''game outcome for home team V: victory L: loss D: draw'''\n",
    "    if f > 0:\n",
    "        return 'V'\n",
    "    elif f < 0:\n",
    "        return 'L'\n",
    "    elif f == 0:\n",
    "        return 'D'\n",
    "    else:\n",
    "        return 'D'\n",
    "\n",
    "def fix_round(f):\n",
    "    '''extract round number or final type'''\n",
    "    if f[:4] == 'Week':\n",
    "        return f[5:7]\n",
    "    elif f[:5] == 'Round':\n",
    "        return f[6:8]\n",
    "    elif f[:10] == 'Qualifiers' or f[:13] == 'Quarterfinals':\n",
    "        return 'QF' # quarter final\n",
    "    elif f[:6] == 'Finals' or f == 'Semifinals' or f == 'Semis' or f == 'Semifinal':\n",
    "        return 'SF' # semi final\n",
    "    elif f[:6] == 'Final ' or f == 'Final':\n",
    "        return 'GF' # grand final\n",
    "    else:\n",
    "        return f\n",
    "    \n",
    "def data_nice(year):\n",
    "    table_nice = []\n",
    "    table_round = []\n",
    "    with open('data/data_' + year + '.txt') as f:\n",
    "        data = bs(f.read())\n",
    "    rows = data.find_all('tr')\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        cols_nice = [ele.text.strip() for ele in cols]\n",
    "        cols_round = [x.text.strip() for x in cols if pattern.match(x.text.strip())]\n",
    "        table_nice.append([ele for ele in cols_nice if ele]) # Get rid of empty values\n",
    "        table_round.append([ele for ele in cols_round if ele]) # Get rid of empty values\n",
    "    df1 = pd.DataFrame(table_nice)\n",
    "    df2 = pd.DataFrame(table_round).fillna(method='ffill')\n",
    "    df = pd.concat([df1, df2], axis=1).dropna()\n",
    "    df['year'] = year\n",
    "    df.columns = ['date','teams','location','time','score','round','year']\n",
    "    df['date'] = df['date'] + ' ' + df['year']\n",
    "    df['home'] = df['teams'].str.split(' v ').str[0]\n",
    "    df['away'] = df['teams'].str.split(' v ').str[1]\n",
    "    df['home'] = df['home'].str.strip()\n",
    "    df['away'] = df['away'].str.strip()\n",
    "    df['fthp'] = df['score'].str.split('-').str[0].astype('int') # full time home points\n",
    "    df['ftap'] = df['score'].str.split('-').str[1].astype('int') # full time away points\n",
    "    df['ftr'] = [outcome(x) for x in df['fthp'] - df['ftap']] # home outcome ftr (full time result)\n",
    "    df['round'] = [fix_round(x) for x in df['round']]\n",
    "    remove_columns = ['teams','score','year','location','time']\n",
    "    df = df.drop(columns=remove_columns)\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframes, cleaning up data:\n",
    "\n",
    "df_2005 = data_nice('2005')\n",
    "df_2006 = data_nice('2006')\n",
    "df_2007 = data_nice('2007')\n",
    "df_2008 = data_nice('2008')\n",
    "df_2009 = data_nice('2009')\n",
    "df_2010 = data_nice('2010')\n",
    "df_2011 = data_nice('2011')\n",
    "df_2012 = data_nice('2012')\n",
    "df_2013 = data_nice('2013')\n",
    "df_2014 = data_nice('2014')\n",
    "df_2015 = data_nice('2015')\n",
    "df_2016 = data_nice('2016')\n",
    "df_2017 = data_nice('2017')\n",
    "df_2018 = data_nice('2018')\n",
    "df_2019 = data_nice('2019')\n",
    "\n",
    "# more fixing data inconsistancies\n",
    "df_2005.loc[(df_2005['date'] == '28 May 2005'), 'round'] = \"GF\" # 2005 no final fixed\n",
    "df_2006.drop(5, inplace=True) # remove bogus final data from 2006\n",
    "df_2018.drop(10, inplace=True) # remove bogus final data from 2018\n",
    "# List of series missing from each year\n",
    "missing_games_2007 = [pd.Series(['12 May 2007', 'SF',\n",
    "                           'Sharks', 'Blues', \n",
    "                           34, 18, 'V'], index=df_2007.columns ) ,\n",
    "                      pd.Series(['12 May 2007', 'SF', \n",
    "                           'Bulls', 'Crusaders', \n",
    "                           27, 12, 'V'], index=df_2007.columns )]\n",
    "\n",
    "missing_games_2008 = [pd.Series(['31 May 2008', 'GF',\n",
    "                           'Crusaders', 'Waratahs', \n",
    "                           20, 12, 'V'], index=df_2008.columns ) ,\n",
    "                      pd.Series(['24 May 2008', 'SF', \n",
    "                           'Waratahs', 'Sharks', \n",
    "                           28, 13, 'V'], index=df_2008.columns ),\n",
    "                      pd.Series(['24 May 2008', 'SF', \n",
    "                           'Crusaders', 'Hurricanes', \n",
    "                           33, 22, 'V'], index=df_2008.columns )]\n",
    "\n",
    "missing_games_2017 = [pd.Series(['21 Jul 2017', 'QF',\n",
    "                           'Brumbies', 'Hurricanes', \n",
    "                           16, 35, 'L'], index=df_2017.columns ) ,\n",
    "                      \n",
    "                      pd.Series(['22 Jul 2017', 'QF', \n",
    "                           'Crusaders', 'Highlanders', \n",
    "                           17, 0, 'V'], index=df_2017.columns ),\n",
    "                      \n",
    "                      pd.Series(['23 Jul 2017', 'QF', \n",
    "                           'Lions', 'Sharks', \n",
    "                           23, 21, 'V'], index=df_2017.columns ),\n",
    "                      \n",
    "                      pd.Series(['23 Jul 2017', 'QF', \n",
    "                           'Stormers', 'Chiefs', \n",
    "                           11, 17, 'L'], index=df_2017.columns )]\n",
    "\n",
    "# Pass a list of series to the append() to add multiple rows to 2007\n",
    "df_2007 = df_2007.append(missing_games_2007 , ignore_index=True)\n",
    "df_2008 = df_2008.append(missing_games_2008 , ignore_index=True)\n",
    "df_2017 = df_2017.append(missing_games_2017 , ignore_index=True)\n",
    "\n",
    "\n",
    "df_2009.at[6, 'home'] = 'Chiefs'\n",
    "df_2009.at[7, 'home'] = 'Bulls'\n",
    "df_2009.at[8, 'home'] = 'Bulls'\n",
    "\n",
    "df_2010.at[4, 'home'] = 'Bulls'\n",
    "\n",
    "df_2013.at[2, 'home'] = 'Crusaders'\n",
    "df_2013.at[3, 'home'] = 'Brumbies'\n",
    "df_2013.at[4, 'home'] = 'Chiefs'\n",
    "df_2013.at[5, 'home'] = 'Bulls'\n",
    "df_2013.at[6, 'home'] = 'Chiefs'\n",
    "\n",
    "df_2014.at[6, 'round'] = 'GF'\n",
    "df_2014.at[2, 'round'] = 'QF'\n",
    "df_2014.at[3, 'round'] = 'QF'\n",
    "\n",
    "df_2015.at[2, 'round'] = 'QF'\n",
    "df_2015.at[3, 'round'] = 'QF'\n",
    "df_2015.at[6, 'round'] = 'GF'\n",
    "\n",
    "df_2016.at[2, 'round'] = 'QF'\n",
    "df_2016.at[3, 'round'] = 'QF'\n",
    "df_2016.at[4, 'round'] = 'QF'\n",
    "df_2016.at[5, 'round'] = 'QF'\n",
    "df_2016.at[8, 'round'] = 'GF'\n",
    "\n",
    "df_2016.at[6, 'home'] = 'Crusaders'\n",
    "df_2016.at[7, 'home'] = 'Lions'\n",
    "\n",
    "df_2018.at[152, 'round'] = 'QF'\n",
    "df_2018.at[153, 'round'] = 'QF'\n",
    "df_2018.at[154, 'round'] = 'QF'\n",
    "df_2018.at[155, 'round'] = 'QF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse dates and sort, reset indexes\n",
    "df_2005.date = df_2005.date.apply(parse_date)\n",
    "df_2006.date = df_2006.date.apply(parse_date)\n",
    "df_2007.date = df_2007.date.apply(parse_date)\n",
    "df_2008.date = df_2008.date.apply(parse_date)\n",
    "df_2009.date = df_2009.date.apply(parse_date)\n",
    "df_2010.date = df_2010.date.apply(parse_date)\n",
    "df_2011.date = df_2011.date.apply(parse_date)\n",
    "df_2012.date = df_2012.date.apply(parse_date)\n",
    "df_2013.date = df_2013.date.apply(parse_date)\n",
    "df_2014.date = df_2014.date.apply(parse_date)\n",
    "df_2015.date = df_2015.date.apply(parse_date)\n",
    "df_2016.date = df_2016.date.apply(parse_date)\n",
    "df_2017.date = df_2017.date.apply(parse_date)\n",
    "df_2018.date = df_2018.date.apply(parse_date)\n",
    "\n",
    "# reset indexes\n",
    "df_2005 = df_2005.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2006 = df_2006.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2007 = df_2007.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2008 = df_2008.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2009 = df_2009.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2010 = df_2010.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2011 = df_2011.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2012 = df_2012.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2013 = df_2013.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2014 = df_2014.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2015 = df_2015.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2016 = df_2016.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2017 = df_2017.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2018 = df_2018.sort_values(by=['date']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get running sum of points and points conceded by round for home and away teams\n",
    "# need to be up to that point/game (hence minus x:)\n",
    "def get_cum_points(df):    \n",
    "    # home team points scored htps\n",
    "    df['htps'] = df.groupby(['home'])['fthp'].apply(lambda x: x.cumsum() - x) \n",
    "    # home team points conceded htpc\n",
    "    df['htpc'] = df.groupby(['home'])['ftap'].apply(lambda x: x.cumsum() - x)\n",
    "    # away team points scored atps\n",
    "    df['atps'] = df.groupby(['away'])['ftap'].apply(lambda x: x.cumsum() - x)\n",
    "    # away team points conceded atpc\n",
    "    df['atpc'] = df.groupby(['away'])['fthp'].apply(lambda x: x.cumsum() - x)\n",
    "    return df\n",
    "\n",
    "# Apply to each dataset\n",
    "df_2005 = get_cum_points(df_2005)\n",
    "df_2006 = get_cum_points(df_2006)\n",
    "df_2007 = get_cum_points(df_2007)\n",
    "df_2008 = get_cum_points(df_2008)\n",
    "df_2009 = get_cum_points(df_2009)\n",
    "df_2010 = get_cum_points(df_2010)\n",
    "df_2011 = get_cum_points(df_2011)\n",
    "df_2012 = get_cum_points(df_2012)\n",
    "df_2013 = get_cum_points(df_2013)\n",
    "df_2014 = get_cum_points(df_2014)\n",
    "df_2015 = get_cum_points(df_2015)\n",
    "df_2016 = get_cum_points(df_2016)\n",
    "df_2017 = get_cum_points(df_2017)\n",
    "df_2018 = get_cum_points(df_2018)\n",
    "\n",
    "def get_home_points(ftr):\n",
    "    '''The most common bonus point system is:\n",
    "    4 points for winning a match.\n",
    "    2 points for drawing a match.\n",
    "    0 points for losing a match.\n",
    "    1 losing bonus point for losing by 7 points (or fewer)\n",
    "    1 try bonus point for scoring (at least) 3 tries more than the opponent.'''\n",
    "    points = 0\n",
    "    if ftr == 'V':\n",
    "        points += 4\n",
    "    elif ftr == 'D':\n",
    "        points += 2\n",
    "    else:\n",
    "        points += 0\n",
    "    return points\n",
    "\n",
    "def get_away_points(ftr):\n",
    "    if ftr == 'V':\n",
    "        return 0\n",
    "    elif ftr == 'D':\n",
    "        return 2\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "def get_cumcomp_points(df):   \n",
    "    df['homepoint'] = [get_home_points(x) for x in df['ftr']]\n",
    "    df['awaypoint'] = [get_away_points(x) for x in df['ftr']]\n",
    "    df['htp'] = df.groupby(['home'])['homepoint'].apply(lambda x: x.cumsum() - x) \n",
    "    df['atp'] = df.groupby(['away'])['awaypoint'].apply(lambda x: x.cumsum() - x)\n",
    "    remove_columns = ['homepoint','awaypoint']\n",
    "    df = df.drop(columns=remove_columns)\n",
    "    return df\n",
    "\n",
    "df_2005 = get_cumcomp_points(df_2005)\n",
    "df_2006 = get_cumcomp_points(df_2006)\n",
    "df_2007 = get_cumcomp_points(df_2007)\n",
    "df_2008 = get_cumcomp_points(df_2008)\n",
    "df_2009 = get_cumcomp_points(df_2009)\n",
    "df_2010 = get_cumcomp_points(df_2010)\n",
    "df_2011 = get_cumcomp_points(df_2011)\n",
    "df_2012 = get_cumcomp_points(df_2012)\n",
    "df_2013 = get_cumcomp_points(df_2013)\n",
    "df_2014 = get_cumcomp_points(df_2014)\n",
    "df_2015 = get_cumcomp_points(df_2015)\n",
    "df_2016 = get_cumcomp_points(df_2016)\n",
    "df_2017 = get_cumcomp_points(df_2017)\n",
    "df_2018 = get_cumcomp_points(df_2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opp_res(x):\n",
    "    if x == 'V':\n",
    "        return 'L'\n",
    "    elif x == 'L':\n",
    "        return 'V'\n",
    "    else:\n",
    "        return 'D'\n",
    "\n",
    "def get_form(df):\n",
    "    ''' gets last game result for last 5 games'''\n",
    "    # home form\n",
    "    df['hm1'] = df.groupby(['home'])['ftr'].shift(1).fillna('M')\n",
    "    df['hm2'] = df.groupby(['home'])['ftr'].shift(2).fillna('M')\n",
    "    df['hm3'] = df.groupby(['home'])['ftr'].shift(3).fillna('M')\n",
    "    df['hm4'] = df.groupby(['home'])['ftr'].shift(4).fillna('M')\n",
    "    df['hm5'] = df.groupby(['home'])['ftr'].shift(5).fillna('M')\n",
    "    # away form need to reverse result to get opposit...\n",
    "    df['am1'] = df.groupby(['away'])['ftr'].shift(1).fillna('M')\n",
    "    df['am2'] = df.groupby(['away'])['ftr'].shift(2).fillna('M')\n",
    "    df['am3'] = df.groupby(['away'])['ftr'].shift(3).fillna('M')\n",
    "    df['am4'] = df.groupby(['away'])['ftr'].shift(4).fillna('M')\n",
    "    df['am5'] = df.groupby(['away'])['ftr'].shift(5).fillna('M')\n",
    "    return df\n",
    "\n",
    "# apply each dataset the form\n",
    "df_2005 = get_form(df_2005)\n",
    "df_2006 = get_form(df_2006)\n",
    "df_2007 = get_form(df_2007)\n",
    "df_2008 = get_form(df_2008)\n",
    "df_2009 = get_form(df_2009)\n",
    "df_2010 = get_form(df_2010)\n",
    "df_2011 = get_form(df_2011)\n",
    "df_2012 = get_form(df_2012)\n",
    "df_2013 = get_form(df_2013)\n",
    "df_2014 = get_form(df_2014)\n",
    "df_2015 = get_form(df_2015)\n",
    "df_2016 = get_form(df_2016)\n",
    "df_2017 = get_form(df_2017)\n",
    "df_2018 = get_form(df_2018)\n",
    "\n",
    "\n",
    "# get round numbers for all rounds including quarters, semis, and finals\n",
    "df_2005['rn'] = df_2005.groupby([True]*len(df_2005))['round'].transform(lambda x: pd.factorize(x)[0]+1)\n",
    "df_2006['rn'] = df_2006.groupby([True]*len(df_2006))['round'].transform(lambda x: pd.factorize(x)[0]+1)\n",
    "df_2007['rn'] = df_2007.groupby([True]*len(df_2007))['round'].transform(lambda x: pd.factorize(x)[0]+1)\n",
    "df_2008['rn'] = df_2008.groupby([True]*len(df_2008))['round'].transform(lambda x: pd.factorize(x)[0]+1)\n",
    "df_2009['rn'] = df_2009.groupby([True]*len(df_2009))['round'].transform(lambda x: pd.factorize(x)[0]+1)\n",
    "df_2010['rn'] = df_2010.groupby([True]*len(df_2010))['round'].transform(lambda x: pd.factorize(x)[0]+1)\n",
    "df_2011['rn'] = df_2011.groupby([True]*len(df_2011))['round'].transform(lambda x: pd.factorize(x)[0]+1)\n",
    "df_2012['rn'] = df_2012.groupby([True]*len(df_2012))['round'].transform(lambda x: pd.factorize(x)[0]+1)\n",
    "df_2013['rn'] = df_2013.groupby([True]*len(df_2013))['round'].transform(lambda x: pd.factorize(x)[0]+1)\n",
    "df_2014['rn'] = df_2014.groupby([True]*len(df_2014))['round'].transform(lambda x: pd.factorize(x)[0]+1)\n",
    "df_2015['rn'] = df_2015.groupby([True]*len(df_2015))['round'].transform(lambda x: pd.factorize(x)[0]+1)\n",
    "df_2016['rn'] = df_2016.groupby([True]*len(df_2016))['round'].transform(lambda x: pd.factorize(x)[0]+1)\n",
    "df_2017['rn'] = df_2017.groupby([True]*len(df_2017))['round'].transform(lambda x: pd.factorize(x)[0]+1)\n",
    "df_2018['rn'] = df_2018.groupby([True]*len(df_2018))['round'].transform(lambda x: pd.factorize(x)[0]+1)\n",
    "\n",
    "\n",
    "\n",
    "# display(df_2005[['ftr','hm1','hm2','am1','am2','home','away']].loc[df_2005['home'] == 'Blues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'round', 'home', 'away', 'fthp', 'ftap', 'ftr', 'htps', 'htpc',\n",
       "       'atps', 'atpc', 'htp', 'atp', 'hm1', 'hm2', 'hm3', 'hm4', 'hm5', 'am1',\n",
       "       'am2', 'am3', 'am4', 'am5', 'rn', 'htformptsstr', 'atformptsstr',\n",
       "       'htformpts', 'atformpts', 'HTWinStreak3', 'HTWinStreak5',\n",
       "       'HTLossStreak3', 'HTLossStreak5', 'ATWinStreak3', 'ATWinStreak5',\n",
       "       'ATLossStreak3', 'ATLossStreak5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playing_stat = pd.concat([df_2005,df_2006,df_2007,df_2008,df_2009,df_2010,df_2011,df_2012,df_2013\n",
    "                          ,df_2014,df_2015,df_2016,df_2017,df_2018],                        \n",
    "                         ignore_index=True)\n",
    "\n",
    "# Gets the form points.\n",
    "def get_form_points(string):\n",
    "    sum = 0\n",
    "    for letter in string:\n",
    "        sum += get_home_points(letter)\n",
    "    return sum\n",
    "\n",
    "playing_stat['htformptsstr'] = playing_stat['hm1'] + playing_stat['hm2'] + playing_stat['hm3'] + playing_stat['hm4'] + playing_stat['hm5']\n",
    "playing_stat['atformptsstr'] = playing_stat['am1'] + playing_stat['am2'] + playing_stat['am3'] + playing_stat['am4'] + playing_stat['am5']\n",
    "\n",
    "playing_stat['htformpts'] = playing_stat['htformptsstr'].apply(get_form_points)\n",
    "playing_stat['atformpts'] = playing_stat['atformptsstr'].apply(get_form_points)\n",
    "\n",
    "# Identify Win/Loss Streaks if any.\n",
    "def get_3game_ws(string):\n",
    "    if string[-3:] == 'VVV':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_5game_ws(string):\n",
    "    if string == 'VVVVV':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_3game_ls(string):\n",
    "    if string[-3:] == 'LLL':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_5game_ls(string):\n",
    "    if string == 'LLLLL':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "playing_stat['HTWinStreak3'] = playing_stat['htformptsstr'].apply(get_3game_ws)\n",
    "playing_stat['HTWinStreak5'] = playing_stat['htformptsstr'].apply(get_5game_ws)\n",
    "playing_stat['HTLossStreak3'] = playing_stat['htformptsstr'].apply(get_3game_ls)\n",
    "playing_stat['HTLossStreak5'] = playing_stat['htformptsstr'].apply(get_5game_ls)\n",
    "\n",
    "playing_stat['ATWinStreak3'] = playing_stat['atformptsstr'].apply(get_3game_ws)\n",
    "playing_stat['ATWinStreak5'] = playing_stat['atformptsstr'].apply(get_5game_ws)\n",
    "playing_stat['ATLossStreak3'] = playing_stat['atformptsstr'].apply(get_3game_ls)\n",
    "playing_stat['ATLossStreak5'] = playing_stat['atformptsstr'].apply(get_5game_ls)\n",
    "\n",
    "playing_stat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Goal Difference\n",
    "playing_stat['htgd'] = playing_stat['htps'] - playing_stat['htpc']\n",
    "playing_stat['atgd'] = playing_stat['atps'] - playing_stat['atpc']\n",
    "\n",
    "# Diff in points\n",
    "playing_stat['diffpts'] = playing_stat['htp'] - playing_stat['atp']\n",
    "playing_stat['diffformpts'] = playing_stat['htformpts'] - playing_stat['atformpts']\n",
    "\n",
    "# Scale DiffPts , DiffFormPts, HTGD, ATGD by Matchweek.\n",
    "cols = ['htgd','atgd','diffpts','diffformpts','htp','atp']\n",
    "playing_stat.rn = playing_stat.rn.astype(float)\n",
    "\n",
    "for col in cols:\n",
    "    playing_stat[col] = playing_stat[col] / playing_stat.rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "playing_stat.to_csv(\"data/final_dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

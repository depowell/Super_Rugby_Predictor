{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018']\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime as dt\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# comprehend list for years\n",
    "years = [str(2000 + i) for i in range(5,19)]\n",
    "this_year = '2019'\n",
    "print(years)\n",
    "\n",
    "# where do we get the data?\n",
    "current_year_url = 'http://www.superrugby.co.nz/Grandstand'\n",
    "url = 'http://www.superrugby.co.nz/Grandstand/HistoricalResults/' # year appends here\n",
    "\n",
    "# getter function\n",
    "def get_rugby_data(url, year):\n",
    "    '''getting data from super rugby website'''\n",
    "    if year == this_year:\n",
    "        x = ''\n",
    "    else:\n",
    "        x = year\n",
    "    page = requests.get(url + x)\n",
    "    soup = bs(page.text, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all previous years data: run this once\n",
    "for i in years:\n",
    "    data = get_rugby_data(url, i)\n",
    "    f = open(\"data/data_\" + i + \".txt\",\"w+\")\n",
    "    f.write(str(data))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get this years data, run this after every round\n",
    "data = get_rugby_data(current_year_url, this_year)\n",
    "f = open(\"data/data_\" + this_year + \".txt\",\"w+\")\n",
    "f.write(str(data))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple functions for cleaning data\n",
    "# regex for finding round names\n",
    "pattern = re.compile(\"^(Round|Week|Semifinal|Final|Qualifiers|Semis)(\\ \\d{1,2})?.*$\")\n",
    "\n",
    "def parse_date(date):\n",
    "    date = dt.datetime.strptime(date, '%d %b %Y')\n",
    "    return date\n",
    "\n",
    "def outcome(f):\n",
    "    '''game outcome for home team V: victory L: loss D: draw'''\n",
    "    if f > 0:\n",
    "        return 'V'\n",
    "    elif f < 0:\n",
    "        return 'L'\n",
    "    elif f == 0:\n",
    "        return 'D'\n",
    "    else:\n",
    "        return 'D'\n",
    "\n",
    "def fix_round(f):\n",
    "    '''extract round number or final type'''\n",
    "    if f[:4] == 'Week':\n",
    "        return f[5:7]\n",
    "    elif f[:5] == 'Round':\n",
    "        return f[6:8]\n",
    "    elif f[:10] == 'Qualifiers' or f[:13] == 'Quarterfinals':\n",
    "        return 'QF' # quarter final\n",
    "    elif f[:6] == 'Finals' or f == 'Semifinals' or f == 'Semis' or f == 'Semifinal':\n",
    "        return 'SF' # semi final\n",
    "    elif f[:6] == 'Final ' or f == 'Final':\n",
    "        return 'GF' # grand final\n",
    "    else:\n",
    "        return f\n",
    "    \n",
    "def data_nice(year):\n",
    "    table_nice = []\n",
    "    table_round = []\n",
    "    with open('data/data_' + year + '.txt') as f:\n",
    "        data = bs(f.read())\n",
    "    rows = data.find_all('tr')\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        cols_nice = [ele.text.strip() for ele in cols]\n",
    "        cols_round = [x.text.strip() for x in cols if pattern.match(x.text.strip())]\n",
    "        table_nice.append([ele for ele in cols_nice if ele]) # Get rid of empty values\n",
    "        table_round.append([ele for ele in cols_round if ele]) # Get rid of empty values\n",
    "    df1 = pd.DataFrame(table_nice)\n",
    "    df2 = pd.DataFrame(table_round).fillna(method='ffill')\n",
    "    df = pd.concat([df1, df2], axis=1).dropna()\n",
    "    df['year'] = year\n",
    "    df.columns = ['date','teams','location','time','score','round','year']\n",
    "    df['date'] = df['date'] + ' ' + df['year']\n",
    "    df['home'] = df['teams'].str.split(' v ').str[0]\n",
    "    df['away'] = df['teams'].str.split(' v ').str[1]\n",
    "    df['home'] = df['home'].str.strip()\n",
    "    df['away'] = df['away'].str.strip()\n",
    "    df['fthp'] = df['score'].str.split('-').str[0].astype('int') # full time home points\n",
    "    df['ftap'] = df['score'].str.split('-').str[1].astype('int') # full time away points\n",
    "    df['ftr'] = [outcome(x) for x in df['fthp'] - df['ftap']] # home outcome ftr (full time result)\n",
    "    df['round'] = [fix_round(x) for x in df['round']]\n",
    "    remove_columns = ['teams','score','year','location','time']\n",
    "    df = df.drop(columns=remove_columns)\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframes, cleaning up data:\n",
    "\n",
    "df_2005 = data_nice('2005')\n",
    "df_2006 = data_nice('2006')\n",
    "df_2007 = data_nice('2007')\n",
    "df_2008 = data_nice('2008')\n",
    "df_2009 = data_nice('2009')\n",
    "df_2010 = data_nice('2010')\n",
    "df_2011 = data_nice('2011')\n",
    "df_2012 = data_nice('2012')\n",
    "df_2013 = data_nice('2013')\n",
    "df_2014 = data_nice('2014')\n",
    "df_2015 = data_nice('2015')\n",
    "df_2016 = data_nice('2016')\n",
    "df_2017 = data_nice('2017')\n",
    "df_2018 = data_nice('2018')\n",
    "df_2019 = data_nice('2019')\n",
    "\n",
    "# more fixing data inconsistancies\n",
    "df_2005.loc[(df_2005['date'] == '28 May 2005'), 'round'] = \"GF\" # 2005 no final fixed\n",
    "df_2006.drop(5, inplace=True) # remove bogus final data from 2006\n",
    "df_2018.drop(10, inplace=True) # remove bogus final data from 2018\n",
    "# List of series missing from each year\n",
    "missing_games_2007 = [pd.Series(['12 May 2007', 'SF',\n",
    "                           'Sharks', 'Blues', \n",
    "                           34, 18, 'V'], index=df_2007.columns ) ,\n",
    "                      pd.Series(['12 May 2007', 'SF', \n",
    "                           'Bulls', 'Crusaders', \n",
    "                           27, 12, 'V'], index=df_2007.columns )]\n",
    "\n",
    "missing_games_2008 = [pd.Series(['31 May 2008', 'GF',\n",
    "                           'Crusaders', 'Waratahs', \n",
    "                           20, 12, 'V'], index=df_2008.columns ) ,\n",
    "                      pd.Series(['24 May 2008', 'SF', \n",
    "                           'Waratahs', 'Sharks', \n",
    "                           28, 13, 'V'], index=df_2008.columns ),\n",
    "                      pd.Series(['24 May 2008', 'SF', \n",
    "                           'Crusaders', 'Hurricanes', \n",
    "                           33, 22, 'V'], index=df_2008.columns )]\n",
    "\n",
    "missing_games_2017 = [pd.Series(['21 Jul 2017', 'QF',\n",
    "                           'Brumbies', 'Hurricanes', \n",
    "                           16, 35, 'L'], index=df_2017.columns ) ,\n",
    "                      \n",
    "                      pd.Series(['22 Jul 2017', 'QF', \n",
    "                           'Crusaders', 'Highlanders', \n",
    "                           17, 0, 'V'], index=df_2017.columns ),\n",
    "                      \n",
    "                      pd.Series(['23 Jul 2017', 'QF', \n",
    "                           'Lions', 'Sharks', \n",
    "                           23, 21, 'V'], index=df_2017.columns ),\n",
    "                      \n",
    "                      pd.Series(['23 Jul 2017', 'QF', \n",
    "                           'Stormers', 'Chiefs', \n",
    "                           11, 17, 'L'], index=df_2017.columns )]\n",
    "\n",
    "# Pass a list of series to the append() to add multiple rows to 2007\n",
    "df_2007 = df_2007.append(missing_games_2007 , ignore_index=True)\n",
    "df_2008 = df_2008.append(missing_games_2008 , ignore_index=True)\n",
    "df_2017 = df_2017.append(missing_games_2017 , ignore_index=True)\n",
    "\n",
    "\n",
    "df_2009.at[6, 'home'] = 'Chiefs'\n",
    "df_2009.at[7, 'home'] = 'Bulls'\n",
    "df_2009.at[8, 'home'] = 'Bulls'\n",
    "\n",
    "df_2010.at[4, 'home'] = 'Bulls'\n",
    "\n",
    "df_2013.at[2, 'home'] = 'Crusaders'\n",
    "df_2013.at[3, 'home'] = 'Brumbies'\n",
    "df_2013.at[4, 'home'] = 'Chiefs'\n",
    "df_2013.at[5, 'home'] = 'Bulls'\n",
    "df_2013.at[6, 'home'] = 'Chiefs'\n",
    "\n",
    "df_2014.at[6, 'round'] = 'GF'\n",
    "df_2014.at[2, 'round'] = 'QF'\n",
    "df_2014.at[3, 'round'] = 'QF'\n",
    "\n",
    "df_2015.at[2, 'round'] = 'QF'\n",
    "df_2015.at[3, 'round'] = 'QF'\n",
    "df_2015.at[6, 'round'] = 'GF'\n",
    "\n",
    "df_2016.at[2, 'round'] = 'QF'\n",
    "df_2016.at[3, 'round'] = 'QF'\n",
    "df_2016.at[4, 'round'] = 'QF'\n",
    "df_2016.at[5, 'round'] = 'QF'\n",
    "df_2016.at[8, 'round'] = 'GF'\n",
    "\n",
    "df_2016.at[6, 'home'] = 'Crusaders'\n",
    "df_2016.at[7, 'home'] = 'Lions'\n",
    "\n",
    "df_2018.at[152, 'round'] = 'QF'\n",
    "df_2018.at[153, 'round'] = 'QF'\n",
    "df_2018.at[154, 'round'] = 'QF'\n",
    "df_2018.at[155, 'round'] = 'QF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse dates and sort, reset indexes\n",
    "df_2005.date = df_2005.date.apply(parse_date)\n",
    "df_2006.date = df_2006.date.apply(parse_date)\n",
    "df_2007.date = df_2007.date.apply(parse_date)\n",
    "df_2008.date = df_2008.date.apply(parse_date)\n",
    "df_2009.date = df_2009.date.apply(parse_date)\n",
    "df_2010.date = df_2010.date.apply(parse_date)\n",
    "df_2011.date = df_2011.date.apply(parse_date)\n",
    "df_2012.date = df_2012.date.apply(parse_date)\n",
    "df_2013.date = df_2013.date.apply(parse_date)\n",
    "df_2014.date = df_2014.date.apply(parse_date)\n",
    "df_2015.date = df_2015.date.apply(parse_date)\n",
    "df_2016.date = df_2016.date.apply(parse_date)\n",
    "df_2017.date = df_2017.date.apply(parse_date)\n",
    "df_2018.date = df_2018.date.apply(parse_date)\n",
    "\n",
    "# reset indexes\n",
    "df_2005 = df_2005.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2006 = df_2006.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2007 = df_2007.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2008 = df_2008.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2009 = df_2009.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2010 = df_2010.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2011 = df_2011.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2012 = df_2012.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2013 = df_2013.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2014 = df_2014.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2015 = df_2015.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2016 = df_2016.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2017 = df_2017.sort_values(by=['date']).reset_index(drop=True)\n",
    "df_2018 = df_2018.sort_values(by=['date']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get running sum of points and points conceded by round for home and away teams\n",
    "# need to be up to that point/game (hence minus x:)\n",
    "def get_cum_points(df):    \n",
    "    # home team points scored htps\n",
    "    df['htps'] = df.groupby(['home'])['fthp'].apply(lambda x: x.cumsum() - x) \n",
    "    # home team points conceded htpc\n",
    "    df['htpc'] = df.groupby(['home'])['ftap'].apply(lambda x: x.cumsum() - x)\n",
    "    # away team points scored atps\n",
    "    df['atps'] = df.groupby(['away'])['ftap'].apply(lambda x: x.cumsum() - x)\n",
    "    # away team points conceded atpc\n",
    "    df['atpc'] = df.groupby(['away'])['fthp'].apply(lambda x: x.cumsum() - x)\n",
    "    return df\n",
    "\n",
    "# Apply to each dataset\n",
    "df_2005 = get_cum_points(df_2005)\n",
    "df_2006 = get_cum_points(df_2006)\n",
    "df_2007 = get_cum_points(df_2007)\n",
    "df_2008 = get_cum_points(df_2008)\n",
    "df_2009 = get_cum_points(df_2009)\n",
    "df_2010 = get_cum_points(df_2010)\n",
    "df_2011 = get_cum_points(df_2011)\n",
    "df_2012 = get_cum_points(df_2012)\n",
    "df_2013 = get_cum_points(df_2013)\n",
    "df_2014 = get_cum_points(df_2014)\n",
    "df_2015 = get_cum_points(df_2015)\n",
    "df_2016 = get_cum_points(df_2016)\n",
    "df_2017 = get_cum_points(df_2017)\n",
    "df_2018 = get_cum_points(df_2018)\n",
    "\n",
    "def get_home_points(ftr):\n",
    "    '''The most common bonus point system is:\n",
    "    4 points for winning a match.\n",
    "    2 points for drawing a match.\n",
    "    0 points for losing a match.\n",
    "    1 losing bonus point for losing by 7 points (or fewer)\n",
    "    1 try bonus point for scoring (at least) 3 tries more than the opponent.'''\n",
    "    points = 0\n",
    "    if ftr == 'V':\n",
    "        points += 4\n",
    "    elif ftr == 'D':\n",
    "        points += 2\n",
    "    else:\n",
    "        points += 0\n",
    "    return points\n",
    "\n",
    "def get_away_points(ftr):\n",
    "    if ftr == 'V':\n",
    "        return 0\n",
    "    elif ftr == 'D':\n",
    "        return 2\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "def get_cumcomp_points(df):   \n",
    "    df['homepoint'] = [get_home_points(x) for x in df['ftr']]\n",
    "    df['awaypoint'] = [get_away_points(x) for x in df['ftr']]\n",
    "    df['htp'] = df.groupby(['home'])['homepoint'].apply(lambda x: x.cumsum() - x) \n",
    "    df['atp'] = df.groupby(['away'])['awaypoint'].apply(lambda x: x.cumsum() - x)\n",
    "    remove_columns = ['homepoint','awaypoint']\n",
    "    df = df.drop(columns=remove_columns)\n",
    "    return df\n",
    "\n",
    "df_2005 = get_cumcomp_points(df_2005)\n",
    "df_2006 = get_cumcomp_points(df_2006)\n",
    "df_2007 = get_cumcomp_points(df_2007)\n",
    "df_2008 = get_cumcomp_points(df_2008)\n",
    "df_2009 = get_cumcomp_points(df_2009)\n",
    "df_2010 = get_cumcomp_points(df_2010)\n",
    "df_2011 = get_cumcomp_points(df_2011)\n",
    "df_2012 = get_cumcomp_points(df_2012)\n",
    "df_2013 = get_cumcomp_points(df_2013)\n",
    "df_2014 = get_cumcomp_points(df_2014)\n",
    "df_2015 = get_cumcomp_points(df_2015)\n",
    "df_2016 = get_cumcomp_points(df_2016)\n",
    "df_2017 = get_cumcomp_points(df_2017)\n",
    "df_2018 = get_cumcomp_points(df_2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opp_res(x):\n",
    "    if x == 'V':\n",
    "        return 'L'\n",
    "    elif x == 'L':\n",
    "        return 'V'\n",
    "    else:\n",
    "        return 'D'\n",
    "\n",
    "def get_form(df):\n",
    "    ''' gets last game result for last 5 games'''\n",
    "    # home form\n",
    "    df['hm1'] = df.groupby(['home'])['ftr'].shift(1).fillna('M')\n",
    "    df['hm2'] = df.groupby(['home'])['ftr'].shift(2).fillna('M')\n",
    "    df['hm3'] = df.groupby(['home'])['ftr'].shift(3).fillna('M')\n",
    "    df['hm4'] = df.groupby(['home'])['ftr'].shift(4).fillna('M')\n",
    "    df['hm5'] = df.groupby(['home'])['ftr'].shift(5).fillna('M')\n",
    "    # away form need to reverse result to get opposit...\n",
    "    df['am1'] = df.groupby(['away'])['ftr'].shift(1).fillna('M')\n",
    "    df['am2'] = df.groupby(['away'])['ftr'].shift(2).fillna('M')\n",
    "    df['am3'] = df.groupby(['away'])['ftr'].shift(3).fillna('M')\n",
    "    df['am4'] = df.groupby(['away'])['ftr'].shift(4).fillna('M')\n",
    "    df['am5'] = df.groupby(['away'])['ftr'].shift(5).fillna('M')\n",
    "    return df\n",
    "\n",
    "# apply each dataset the form\n",
    "df_2005 = get_form(df_2005)\n",
    "df_2006 = get_form(df_2006)\n",
    "df_2007 = get_form(df_2007)\n",
    "df_2008 = get_form(df_2008)\n",
    "df_2009 = get_form(df_2009)\n",
    "df_2010 = get_form(df_2010)\n",
    "df_2011 = get_form(df_2011)\n",
    "df_2012 = get_form(df_2012)\n",
    "df_2013 = get_form(df_2013)\n",
    "df_2014 = get_form(df_2014)\n",
    "df_2015 = get_form(df_2015)\n",
    "df_2016 = get_form(df_2016)\n",
    "df_2017 = get_form(df_2017)\n",
    "df_2018 = get_form(df_2018)\n",
    "\n",
    "# display(df_2005[['ftr','hm1','hm2','am1','am2','home','away']].loc[df_2005['home'] == 'Blues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home</th>\n",
       "      <th>away</th>\n",
       "      <th>fthp</th>\n",
       "      <th>ftap</th>\n",
       "      <th>ftr</th>\n",
       "      <th>htp</th>\n",
       "      <th>atp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Highlanders</td>\n",
       "      <td>Blues</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waratahs</td>\n",
       "      <td>Chiefs</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stormers</td>\n",
       "      <td>Sharks</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brumbies</td>\n",
       "      <td>Crusaders</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reds</td>\n",
       "      <td>Hurricanes</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          home        away  fthp  ftap ftr  htp  atp\n",
       "0  Highlanders       Blues    14    30   L    0    0\n",
       "1     Waratahs      Chiefs    25     7   V    0    0\n",
       "2     Stormers      Sharks    26    12   V    0    0\n",
       "3     Brumbies   Crusaders    32    21   V    0    0\n",
       "4         Reds  Hurricanes    10    24   L    0    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_2005[['home','away','fthp','ftap','ftr','htp','atp']].head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
